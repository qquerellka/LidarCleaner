{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68994e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting open3d\n",
      "  Downloading open3d-0.19.0-cp311-cp311-manylinux_2_31_x86_64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (1.26.4)\n",
      "Collecting dash>=2.6.0 (from open3d)\n",
      "  Downloading dash-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: werkzeug>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.3)\n",
      "Requirement already satisfied: flask>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.1.1)\n",
      "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (5.10.4)\n",
      "Collecting configargparse (from open3d)\n",
      "  Downloading configargparse-1.7.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: ipywidgets>=8.0.4 in /usr/local/lib/python3.11/dist-packages (from open3d) (8.1.5)\n",
      "Collecting addict (from open3d)\n",
      "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (11.2.1)\n",
      "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.11/dist-packages (from open3d) (3.7.2)\n",
      "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.11/dist-packages (from open3d) (2.2.3)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from open3d) (6.0.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.11/dist-packages (from open3d) (1.2.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open3d) (4.67.1)\n",
      "Collecting pyquaternion (from open3d)\n",
      "  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (8.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (4.14.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (2.32.4)\n",
      "Collecting retrying (from dash>=2.6.0->open3d)\n",
      "  Downloading retrying-1.4.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash>=2.6.0->open3d) (75.2.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (8.2.1)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask>=3.0.0->open3d) (3.0.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.15)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (25.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->open3d) (2.9.0.post0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (4.24.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7.0->open3d) (5.8.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->open3d) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->open3d) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->open3d) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->open3d) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->open3d) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->open3d) (2.4.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->open3d) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->open3d) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->open3d) (3.6.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.51)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.19.2)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.25.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.8)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.17.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.23.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.0->open3d) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.0->open3d) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.0->open3d) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.18.0->open3d) (2024.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=2.6.0->open3d) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=2.6.0->open3d) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=2.6.0->open3d) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->dash>=2.6.0->open3d) (2025.6.15)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.18.0->open3d) (2024.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
      "Downloading open3d-0.19.0-cp311-cp311-manylinux_2_31_x86_64.whl (447.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.7/447.7 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dash-3.2.0-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Downloading configargparse-1.7.1-py3-none-any.whl (25 kB)\n",
      "Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
      "Downloading retrying-1.4.2-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: addict, retrying, configargparse, dash, pyquaternion, open3d\n",
      "Successfully installed addict-2.4.0 configargparse-1.7.1 dash-3.2.0 open3d-0.19.0 pyquaternion-0.9.9 retrying-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5145d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import open3d as o3d\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from scipy.spatial import cKDTree\n",
    "import warnings\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b1187ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено 205 pairs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "def load_preprocessed_pairs(input_dir):\n",
    "    pairs = []\n",
    "    npz_files = sorted(glob.glob(os.path.join(input_dir, '*.npz')))  # pair_0.npz, pair_1.npz...\n",
    "    for file in npz_files:\n",
    "        data = np.load(file)\n",
    "        static = data['static']\n",
    "        dynamic = data['dynamic']\n",
    "        pairs.append((static, dynamic))\n",
    "    return pairs\n",
    "\n",
    "pairs = load_preprocessed_pairs('/kaggle/input/kitti360-preprocessed-pairs')\n",
    "print(f\"Загружено {len(pairs)} pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f1fc8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "split_idx = int(0.9 * len(pairs))\n",
    "train_pairs = pairs[:split_idx]\n",
    "val_pairs = pairs[split_idx:]\n",
    "print(len(train_pairs), len(val_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42cc34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KittiDynamicDataset(Dataset):\n",
    "    def __init__(self, pairs, num_points=4096, voxel_size=0.05, dynamic_r=0.1, is_train=True):\n",
    "        self.pairs = pairs\n",
    "        self.num_points = num_points\n",
    "        self.voxel_size = voxel_size\n",
    "        self.dynamic_r = dynamic_r\n",
    "        self.is_train = is_train\n",
    "        self.dynamic_ratio = 0.7 if is_train else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        static, dynamic = self.pairs[idx]\n",
    "\n",
    "        if len(static) > 0 and len(dynamic) > 0:\n",
    "            tree = cKDTree(dynamic)\n",
    "            dist, _ = tree.query(static, k=1)\n",
    "            keep_mask = dist > self.dynamic_r\n",
    "            static_clean = static[keep_mask]\n",
    "        else:\n",
    "            static_clean = static\n",
    "\n",
    "        if len(dynamic) > 0:\n",
    "            all_points = np.vstack([static_clean, dynamic])\n",
    "            labels = np.hstack([\n",
    "                np.zeros(len(static_clean), dtype=np.int64),\n",
    "                np.ones(len(dynamic), dtype=np.int64)\n",
    "            ])\n",
    "        else:\n",
    "            all_points = static_clean\n",
    "            labels = np.zeros(len(static_clean), dtype=np.int64)\n",
    "\n",
    "        if self.is_train and self.dynamic_ratio is not None and self.dynamic_ratio > 0:\n",
    "            num_dynamic = int(self.num_points * self.dynamic_ratio)\n",
    "            num_static = self.num_points - num_dynamic\n",
    "\n",
    "            if len(dynamic) > 0:\n",
    "                dynamic_choice = np.random.choice(len(dynamic), num_dynamic, replace=True)\n",
    "                dynamic_pts = dynamic[dynamic_choice]\n",
    "                dynamic_lbls = np.ones(num_dynamic, dtype=np.int64)\n",
    "            else:\n",
    "                dynamic_pts = np.empty((0, dynamic.shape[1])) \n",
    "                dynamic_lbls = np.array([])\n",
    "                num_dynamic = 0 \n",
    "                num_static = self.num_points \n",
    "\n",
    "            # Undersample static\n",
    "            if len(static_clean) >= num_static:\n",
    "                static_choice = np.random.choice(len(static_clean), num_static, replace=False)\n",
    "            else:\n",
    "                static_choice = np.random.choice(len(static_clean), num_static, replace=True)  # Уже есть, ок для мало static\n",
    "            static_pts = static_clean[static_choice]\n",
    "            static_lbls = np.zeros(num_static, dtype=np.int64)\n",
    "\n",
    "            all_points = np.vstack([static_pts, dynamic_pts])\n",
    "            labels = np.hstack([static_lbls, dynamic_lbls])\n",
    "\n",
    "            perm = np.random.permutation(self.num_points)\n",
    "            pts = all_points[perm]\n",
    "            lbls = labels[perm]\n",
    "\n",
    "        else: \n",
    "            if len(all_points) >= self.num_points:\n",
    "                choice = np.random.choice(len(all_points), self.num_points, replace=False)\n",
    "            else:\n",
    "                choice = np.random.choice(len(all_points), self.num_points, replace=True)\n",
    "            pts = all_points[choice]\n",
    "            lbls = labels[choice]\n",
    "            perm = np.random.permutation(self.num_points)\n",
    "            pts = pts[perm]\n",
    "            lbls = lbls[perm]\n",
    "        # pts = all_points[choice]\n",
    "        # lbls = labels[choice]\n",
    "        # print(len(pts))\n",
    "        xyz = pts[:, :3] \n",
    "        xyz_mean = np.mean(xyz, axis=0, keepdims=True) \n",
    "        xyz = xyz - xyz_mean        \n",
    "        xyz_max = np.max(np.abs(xyz))\n",
    "        xyz = xyz / (xyz_max + 1e-6) \n",
    "\n",
    "        pts[:, :3] = xyz\n",
    "\n",
    "        rgb = pts[:, 3:6]\n",
    "        if np.max(rgb) > 1.0: \n",
    "            rgb = rgb / 255.0\n",
    "\n",
    "        rgb_mean = np.mean(rgb, axis=0, keepdims=True)\n",
    "        rgb_std = np.std(rgb, axis=0, keepdims=True) + 1e-6\n",
    "        rgb = (rgb - rgb_mean) / rgb_std\n",
    "        pts[:, 3:6] = rgb\n",
    "        \n",
    "        # print(pts.shape)\n",
    "        \n",
    "        # if pts.shape[1] < 9:\n",
    "        #     pad_width = 9 - pts.shape[1]\n",
    "        #     pts = np.hstack([pts, np.ones((self.num_points, pad_width))])\n",
    "\n",
    "        # aug\n",
    "        if self.is_train and len(dynamic) > 0:\n",
    "            jitter = np.random.normal(0, 0.02, size=(num_dynamic, 3))\n",
    "            dynamic_pts[:, :3] += jitter  \n",
    "\n",
    "        # print(pts)\n",
    "        return torch.tensor(pts, dtype=torch.float32), torch.tensor(lbls, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c03170e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Pointnet_Pointnet2_pytorch'...\n",
      "remote: Enumerating objects: 842, done.\u001b[K\n",
      "remote: Total 842 (delta 0), reused 0 (delta 0), pack-reused 842 (from 1)\u001b[K\n",
      "Receiving objects: 100% (842/842), 68.77 MiB | 38.21 MiB/s, done.\n",
      "Resolving deltas: 100% (485/485), done.\n",
      "/kaggle/working/Pointnet_Pointnet2_pytorch\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/yanx27/Pointnet_Pointnet2_pytorch.git\n",
    "%cd Pointnet_Pointnet2_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7677fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22245bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.pointnet2_sem_seg import get_model, get_loss\n",
    "\n",
    "num_classes = 2 \n",
    "model = get_model(num_classes=num_classes).to(device) #[B, num_classes, N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13a5e49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"/kaggle/input/lidarsegmmodel-17/best_model.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c471dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        return focal_loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e727c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_loss(pred, target, num_classes=2, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Smooth IoU loss Pred: [B*N, C] после softmax, target: [B*N] long.\n",
    "    \"\"\"\n",
    "    pred = F.softmax(pred, dim=1)  # [B*N, C]\n",
    "    one_hot_target = F.one_hot(target, num_classes=num_classes).float()  # [B*N, C]\n",
    "    \n",
    "    intersection = (pred * one_hot_target).sum(dim=0)  # По классам [C]\n",
    "    union = (pred + one_hot_target).sum(dim=0) - intersection  # [C]\n",
    "    \n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return 1 - iou.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec89f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "try:\n",
    "    from itertools import ifilterfalse\n",
    "except ImportError:  # py3k\n",
    "    from itertools import filterfalse as ifilterfalse\n",
    "\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    p = len(gt_sorted)\n",
    "    gts = gt_sorted.sum()\n",
    "    intersection = gts - gt_sorted.float().cumsum(0)\n",
    "    union = gts + (1 - gt_sorted).float().cumsum(0)\n",
    "    jaccard = 1. - intersection / union\n",
    "    if p > 1:  # cover 1-pixel case\n",
    "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
    "    return jaccard\n",
    "\n",
    "def lovasz_softmax_flat(probas, labels, classes='present'):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n",
    "    \"\"\"\n",
    "    if probas.numel() == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return probas * 0.\n",
    "    C = probas.size(1)\n",
    "    losses = []\n",
    "    class_to_sum = list(range(C)) if classes in ['all', 'present'] else classes\n",
    "    for c in class_to_sum:\n",
    "        fg = (labels == c).float()  # foreground for class c\n",
    "        if (classes == 'present' and fg.sum() == 0):\n",
    "            continue\n",
    "        if C == 1:\n",
    "            if len(classes) > 1:\n",
    "                raise ValueError(\"Sigmoid output possible only with 1 class\")\n",
    "            class_pred = probas[:, 0]\n",
    "        else:\n",
    "            class_pred = probas[:, c]\n",
    "        errors = (Variable(fg) - class_pred).abs()\n",
    "        errors_sorted, perm = torch.sort(errors, 0, descending=True)\n",
    "        perm = perm.data\n",
    "        fg_sorted = fg[perm]\n",
    "        losses.append(torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted))))\n",
    "    return mean(losses)\n",
    "\n",
    "def flatten_probas(probas, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch\n",
    "    \"\"\"\n",
    "    if probas.dim() == 3:\n",
    "        # assumes output of a sigmoid layer\n",
    "        B, H, W = probas.size()\n",
    "        probas = probas.view(B, 1, H, W)\n",
    "    B, C, H, W = probas.size()\n",
    "    probas = probas.permute(0, 2, 3, 1).contiguous().view(-1, C)  # B * H * W, C = P, C\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return probas, labels\n",
    "    valid = (labels != ignore)\n",
    "    vprobas = probas[valid.nonzero().squeeze()]\n",
    "    vlabels = labels[valid]\n",
    "    return vprobas, vlabels\n",
    "\n",
    "def lovasz_softmax(probas, labels, classes='present', per_image=False, ignore=None):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1).\n",
    "              Interpreted as binary (sigmoid) output with outputs of size [B, H, W].\n",
    "      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class labels\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = mean(lovasz_softmax_flat(*flatten_probas(prob.unsqueeze(0), lab.unsqueeze(0), ignore), classes=classes)\n",
    "                          for prob, lab in zip(probas, labels))\n",
    "    else:\n",
    "        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore), classes=classes)\n",
    "    return loss\n",
    "\n",
    "def mean(l, ignore_nan=False, empty=0):\n",
    "    \"\"\"\n",
    "    nanmean compatible with torch.tensor\n",
    "    \"\"\"\n",
    "    l = iter(l)\n",
    "    if ignore_nan:\n",
    "        l = ifilterfalse(np.isnan, l)\n",
    "    try:\n",
    "        n = 1\n",
    "        acc = next(l)\n",
    "    except StopIteration:\n",
    "        if empty == 'raise':\n",
    "            raise\n",
    "        return empty\n",
    "    for n, v in enumerate(l, 2):\n",
    "        acc += v\n",
    "    if n == 1:\n",
    "        return acc\n",
    "    return acc / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27450c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_seen = 0\n",
    "    num_classes = 2\n",
    "    total_correct_class = [0 for _ in range(num_classes)]\n",
    "    total_seen_class = [0 for _ in range(num_classes)]\n",
    "    total_iou_deno_class = [0 for _ in range(num_classes)]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for pts, lbls in dataloader:\n",
    "            pts, lbls = pts.to(device), lbls.to(device)\n",
    "            pts = pts.permute(0, 2, 1).float()  # [B, D, N]\n",
    "\n",
    "            pred, _ = model(pts)                # [B, N, C]\n",
    "            B, N, C = pred.shape\n",
    "\n",
    "            pred_flat = pred.reshape(B * N, C)\n",
    "            lbls_flat = lbls.reshape(B * N)\n",
    "\n",
    "            loss_ce = criterion(pred_flat, lbls_flat)\n",
    "            # loss_iou = iou_loss(pred_flat, lbls_flat) \n",
    "            # total_loss = loss_ce + 0.6 * loss_iou\n",
    "            probas = F.softmax(pred_flat, dim=1)  # [B*N, C]\n",
    "            loss_lovasz = lovasz_softmax_flat(probas, lbls_flat, classes='present') \n",
    "            total_loss = (0.6 * loss_ce + 0.4 * loss_lovasz).item()\n",
    "\n",
    "            pred_labels = pred.argmax(dim=2)    # [B, N]\n",
    "            correct = (pred_labels == lbls).sum().item()\n",
    "            total_correct += correct\n",
    "            total_seen += B * N\n",
    "\n",
    "            # IoU подсчёт\n",
    "            pred_np = pred_labels.cpu().numpy().reshape(-1)\n",
    "            lbls_np = lbls.cpu().numpy().reshape(-1)\n",
    "\n",
    "            for l in range(num_classes):\n",
    "                total_seen_class[l] += np.sum(lbls_np == l)\n",
    "                total_correct_class[l] += np.sum((pred_np == l) & (lbls_np == l))\n",
    "                total_iou_deno_class[l] += np.sum((pred_np == l) | (lbls_np == l))\n",
    "\n",
    "    acc = total_correct / total_seen\n",
    "    iou_per_class = np.array(total_correct_class) / (np.array(total_iou_deno_class) + 1e-6)\n",
    "    miou = np.mean(iou_per_class)\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    model.train()\n",
    "    return avg_loss, acc, miou, iou_per_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c98dbfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_pairs[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be338ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KittiDynamicDataset(train_pairs, num_points=16384, voxel_size=0.1)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
    "\n",
    "val_dataset = KittiDynamicDataset(val_pairs, num_points=16384, voxel_size=0.1, is_train=False) \n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# criterion = get_loss().to(device)\n",
    "# criterion = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 10.0]).to(device))\n",
    "criterion = FocalLoss(alpha=0.75, gamma=2.0)  # alpha >0.5 для minority\n",
    "\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)  # По mIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9e764c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 10/23 [17:07<29:28, 136.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 10 | curr mean loss 0.17167039960622787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 20/23 [33:34<04:05, 81.67s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 20 | curr mean loss 0.16753641106188297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [43:01<00:00, 112.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Dynamic Ratio: 0.4 | Loss: 0.1679071839088979 | val_loss=0.0640 | acc=0.9258 | mIoU=0.5382\n",
      "New best mIoU: 0.5382, model saved to /kaggle/working/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 10/23 [20:25<28:30, 131.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 10 | curr mean loss 0.16773422062397003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 20/23 [41:22<04:38, 92.69s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 20 | curr mean loss 0.16559298112988471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [47:45<00:00, 124.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Dynamic Ratio: 0.30000000000000004 | Loss: 0.16862137162167093 | val_loss=0.0636 | acc=0.9194 | mIoU=0.5284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 10/23 [20:58<22:11, 102.44s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 10 | curr mean loss 0.16431291848421098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 20/23 [34:02<03:04, 61.52s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 20 | curr mean loss 0.1622612565755844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [44:54<00:00, 117.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Dynamic Ratio: 0.3 | Loss: 0.16197507083415985 | val_loss=0.0635 | acc=0.9531 | mIoU=0.5094\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "model.train()\n",
    "best_miou = -float('inf')  \n",
    "best_model_path = \"/kaggle/working/best_model.pth\"\n",
    "for epoch in range(3):\n",
    "    count = 0\n",
    "    total_loss = 0\n",
    "    losses_cnt = 0\n",
    "    train_dataset.dynamic_ratio = max(0.3, 0.4 - epoch * 0.1) #0.7\n",
    "    for pts, lbls in tqdm.tqdm(train_dataloader):\n",
    "        pts, lbls = torch.Tensor(pts.to(device)), torch.Tensor(lbls.to(device))\n",
    "        pts = pts.permute(0, 2, 1).float() \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred, trans_feat = model(pts)       # pred: [B, N, C]\n",
    "        B, N, C = pred.shape\n",
    "        pred_flat = pred.reshape(B * N, C)     # [B*N, C]\n",
    "        lbls_flat = lbls.reshape(B * N)        # [B*N]\n",
    "\n",
    "        # 1. # Another loss vers (bc + active weights)\n",
    "        # class_counts = torch.bincount(lbls_flat, minlength=2).float()\n",
    "        # class_probs = class_counts / class_counts.sum()\n",
    "        # weights = 1.0 / (class_probs + 1e-6)\n",
    "        # weights = weights / weights.sum() * 2  # Нормализуйте на num_classes\n",
    "        # loss = F.cross_entropy(pred_flat, lbls_flat, weight=weights)\n",
    "\n",
    "        # 2. Focal + IOU\n",
    "        # loss_ce = criterion(pred_flat, lbls_flat)\n",
    "        # loss_iou = iou_loss(pred_flat, lbls_flat) \n",
    "        # loss = loss_ce + 0.7 * loss_iou  # λ=0.5 - 1.0\n",
    "\n",
    "        # 3. Lovasz-Softmax loss\n",
    "        loss_ce = criterion(pred_flat, lbls_flat)\n",
    "        probas = F.softmax(pred_flat, dim=1)  # [B*N, C]\n",
    "        loss_lovasz = lovasz_softmax_flat(probas, lbls_flat, classes='present')\n",
    "        loss = 0.6 * loss_ce + 0.4 * loss_lovasz  \n",
    "\n",
    "\n",
    "        # loss = criterion(pred_flat, lbls_flat)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        losses_cnt+=1\n",
    "        count+=1\n",
    "        if (count%10 == 0):\n",
    "            print(f\"Count: {count} | curr mean loss {total_loss/count}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # print(f\"Epoch {epoch} | Loss: {total_loss/len(train_dataloader)}\")\n",
    "    val_loss, val_acc, val_miou, iou_per_class = validate(model, val_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1} | Dynamic Ratio: {train_dataset.dynamic_ratio} | Loss: {total_loss/len(train_dataloader)} | val_loss={val_loss:.4f} | acc={val_acc:.4f} | mIoU={val_miou:.4f}\")\n",
    "\n",
    "\n",
    "    if val_miou > best_miou:\n",
    "        best_miou = val_miou\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"New best mIoU: {best_miou:.4f}, model saved to {best_model_path}\")\n",
    "    # scheduler.step(val_miou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfe87d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"/kaggle/working/final_model.pth\")\n",
    "print(\"Final model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6d4cb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_utils  provider.py\t\t    test_semseg.py\t     visualizer\n",
      "LICENSE     README.md\t\t    train_classification.py\n",
      "log\t    test_classification.py  train_partseg.py\n",
      "models\t    test_partseg.py\t    train_semseg.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "709dd97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def visualize_sample(features, labels, sample_idx=0, color_by='rgb', figsize=(10, 8)):\n",
    "    \"\"\"\n",
    "    Simple visualization of a point cloud sample.\n",
    "    \n",
    "    Args:\n",
    "        features (np.array): (N, 6) - XYZ + RGB\n",
    "        labels (np.array): (N,) - semantic labels\n",
    "        sample_idx (int): For title\n",
    "        color_by (str): 'rgb' or 'labels'\n",
    "        figsize (tuple): Plot size\n",
    "    \"\"\"\n",
    "    points = features[:, :3]  \n",
    "    rgb = features[:, 3:]     \n",
    "    \n",
    "\n",
    "    label_colors = {\n",
    "        0: [0.5, 0.5, 0.5],  \n",
    "        1: [1.0, 0.0, 0.0],  \n",
    "        \n",
    "    }\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    # 3D plot\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    if color_by == 'rgb':\n",
    "        ax.scatter(points[:, 0], points[:, 1], points[:, 2], c=rgb, s=2, alpha=0.6)\n",
    "        ax.set_title(f'Sample {sample_idx}: 3D RGB')\n",
    "    else:\n",
    "        colors_plot = np.array([label_colors.get(int(l), [0.5, 0.5, 0.5]) for l in labels])\n",
    "        ax.scatter(points[:, 0], points[:, 1], points[:, 2], c=colors_plot, s=2, alpha=0.6)\n",
    "        ax.set_title(f'Sample {sample_idx}: 3D by Labels')\n",
    "    \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    fig2d = plt.figure(figsize=(10, 8))\n",
    "    ax2d = fig2d.add_subplot(111)\n",
    "    if color_by == 'rgb':\n",
    "        ax2d.scatter(points[:, 0], points[:, 1], c=rgb, s=1, alpha=0.6)\n",
    "        ax2d.set_title(f'Sample {sample_idx}: Top-Down RGB')\n",
    "    else:\n",
    "        ax2d.scatter(points[:, 0], points[:, 1], c=colors_plot, s=1, alpha=0.6)\n",
    "        ax2d.set_title(f'Sample {sample_idx}: Top-Down by Labels')\n",
    "    \n",
    "    ax2d.set_xlabel('X')\n",
    "    ax2d.set_ylabel('Y')\n",
    "    ax2d.set_aspect('equal')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(unique, counts, alpha=0.7)\n",
    "    plt.title(f'Sample {sample_idx}: Label Counts')\n",
    "    plt.xlabel('Label ID')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd94b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1, 6):\n",
    "    features, labels = val_dataset[idx]    \n",
    "    # print(features[: :6].shape, labels.shape)\n",
    "    # visualize_sample(features[:, :6], labels, color_by='rgb')\n",
    "    visualize_sample(features[:, :6], labels, color_by='labels')\n",
    "\n",
    "    # for i in range(len(train_dataset)):\n",
    "    #     features, labels = train_dataset[i]\n",
    "    #     visualize_sample(features[:, :6], labels, color_by='labels')\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    features, labels = val_dataset[idx]\n",
    "    features = features.unsqueeze(0).permute(0, 2, 1).float().to(device)  # [1, 9, 16384]\n",
    "    with torch.no_grad():\n",
    "        pred, _ = model(features)\n",
    "        pred_labels = pred.argmax(dim=2).cpu().numpy().reshape(-1)  # [16384]\n",
    "        # print(pred_labels[:10])\n",
    "    # print(features[0].permute(1, 0).shape, pred_labels.shape) # [16384, 9], [16384]\n",
    "    visualize_sample(features[0].permute(1, 0).cpu().numpy(), pred_labels, color_by='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26080c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: Starting upload for file best_model.pth\n",
      "Upload successful: best_model.pth (4MB)\n",
      "Starting upload for file final_model.pth\n",
      "Upload successful: final_model.pth (4MB)\n",
      "Starting upload for file Pointnet_Pointnet2_pytorch.zip\n",
      "Upload successful: Pointnet_Pointnet2_pytorch.zip (137MB)\n",
      "Starting upload for file .virtual_documents.zip\n",
      "Upload successful: .virtual_documents.zip (22B)\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/datasets/vadimcvbnqq/lidarSegmModel-17\n",
      "\n",
      "Errors: \n",
      "  0%|          | 0.00/3.77M [00:00<?, ?B/s]\n",
      "100%|██████████| 3.77M/3.77M [00:00<00:00, 14.4MB/s]\n",
      "\n",
      "  0%|          | 0.00/3.77M [00:00<?, ?B/s]\n",
      "100%|██████████| 3.77M/3.77M [00:00<00:00, 16.7MB/s]\n",
      "\n",
      "  0%|          | 0.00/137M [00:00<?, ?B/s]\n",
      " 17%|█▋        | 22.7M/137M [00:00<00:00, 226MB/s]\n",
      " 32%|███▏      | 44.3M/137M [00:00<00:00, 191MB/s]\n",
      " 46%|████▌     | 62.8M/137M [00:00<00:00, 170MB/s]\n",
      " 58%|█████▊    | 79.3M/137M [00:00<00:00, 159MB/s]\n",
      " 69%|██████▉   | 94.6M/137M [00:00<00:00, 158MB/s]\n",
      " 80%|████████  | 110M/137M [00:00<00:00, 157MB/s] \n",
      " 92%|█████████▏| 126M/137M [00:00<00:00, 161MB/s]\n",
      "100%|██████████| 137M/137M [00:01<00:00, 122MB/s]\n",
      "\n",
      "  0%|          | 0.00/22.0 [00:00<?, ?B/s]\n",
      "100%|██████████| 22.0/22.0 [00:00<00:00, 120B/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "KAGGLE_JSON_PATH = '/kaggle/input/kaggle2/kaggle.json'  \n",
    "\n",
    "!mkdir -p /root/.kaggle\n",
    "!cp {KAGGLE_JSON_PATH} /root/.kaggle/\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "torch.save(model.state_dict(), '/kaggle/working/final_model.pth')\n",
    "\n",
    "dataset_metadata = {\n",
    "    \"title\": \"My-Trained-Model-Weights-17\",\n",
    "    \"id\": \"us/lidarSegmModel-17\",  \n",
    "    \"licenses\": [{\"name\": \"CC0-1.0\"}],\n",
    "    \"description\": \"Trained model weights from my project\"\n",
    "}\n",
    "\n",
    "with open('/kaggle/working/dataset-metadata.json', 'w') as f:\n",
    "    json.dump(dataset_metadata, f)\n",
    "\n",
    "result = subprocess.run([\n",
    "    'kaggle', 'datasets', 'create',\n",
    "    '-p', '/kaggle/working',\n",
    "    '--dir-mode', 'zip'\n",
    "], capture_output=True, text=True)\n",
    "\n",
    "print(\"Output:\", result.stdout)\n",
    "print(\"Errors:\", result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5122a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
